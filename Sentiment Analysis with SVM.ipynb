{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c894df-93d6-4d01-adaf-0828de152451",
   "metadata": {},
   "source": [
    "We will be predicting the sentiment (positive or negative) of a single sentence taken from a review of a \r\n",
    "movie, restaurant, or product. The data set consists of 3000 labeled sentences, which we divide into a \r\n",
    "training set of size 2500 and a test set of size 500. We have already used a logistic regression classifier. Now, \r\n",
    "we will use a support vector machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "823259b0-6f36-46eb-8f32-f8075757de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import numpy as np \n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt \n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn import svm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a66c332-ceeb-45f0-bb0b-899acfc47521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and preprocessing the data \n",
    "#Read in the data set: \n",
    "with open(r\"K:\\DATA SCIENCE\\DataSets\\TopMentor Datasets\\data\\full_set.txt\") as f: content = f.readlines() \n",
    "#Remove leading and trailing white space: \n",
    "content = [x.strip() for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f6ba82e-35ac-488b-9175-fb76400eb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the sentences from the labels: \n",
    "sentences = [x.split(\"\\t\")[0] for x in content] \n",
    "labels = [x.split(\"\\t\")[1] for x in content] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d183834-5d8f-4b6a-b317-a329cde3533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the labels from '0 versus 1' to '-1 versus 1': \n",
    "y = np.array(labels, dtype='int8') \n",
    "y = 2*y - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff6fcd7-25e2-45a6-acc5-b6cdd247dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us define a function, \"full_remove\" that takes a string x \n",
    "# and a list of characters from a removal_list and returns with all the \n",
    "# characters in removal_list replaced by ' '. \n",
    "def full_remove(x, removal_list): \n",
    "    for w in removal_list: \n",
    "        x = x.replace(w, ' ') \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d751f126-04a7-4f0c-aeb2-1e0ed51bd545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove digits: \n",
    "digits = [str(x) for x in range(10)] \n",
    "digit_less = [full_remove(x, digits) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c45225d-02df-42bd-a0ed-d5d1097dff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove punctuation: \n",
    "punc_less = [full_remove(x, list(string.punctuation)) for x in digit_less]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7491d4f4-698f-447a-8f6f-e7c1c259704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make everything lower-case: \n",
    "sents_lower = [x.lower() for x in punc_less] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b634e9ed-36ee-4861-8d09-a1805d2d560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our stop words: \n",
    "stop_set = set(['the', 'a', 'an', 'i', 'he', 'she', 'they', 'to', 'of', 'it', 'from']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f7d882b-94d2-48e1-9ddf-9488fefeea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stop words \n",
    "sents_split = [x.split() for x in sents_lower] \n",
    "sents_processed = [\" \".join(list(filter(lambda a: a not in stop_set, x))) for x in sents_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ef4dd3-8098-4d3e-ac57-789c5bdb18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform to bag of words representation: \n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, \n",
    "preprocessor = None, stop_words = None, max_features = 4500) \n",
    "data_features = vectorizer.fit_transform(sents_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb9e212-b083-4680-9540-c582a3414d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append '1' to the end of each vector. \n",
    "data_mat = data_features.toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d89306d6-64b7-447d-a3d4-68c66b17c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (2500, 4500)\n",
      "test data:  (500, 4500)\n"
     ]
    }
   ],
   "source": [
    "#Split the data into testing and training sets: \n",
    "np.random.seed(0) \n",
    "test_inds = np.append(np.random.choice((np.where(y==-1))[0], 250, replace=False), np.random.choice((np.where(y==1))[0], 250, replace=False)) \n",
    "train_inds = list(set(range(len(labels))) - set(test_inds)) \n",
    "train_data = data_mat[train_inds,] \n",
    "train_labels = y[train_inds] \n",
    "test_data = data_mat[test_inds,] \n",
    "test_labels = y[test_inds] \n",
    "print(\"train data: \", train_data.shape) \n",
    "print(\"test data: \", test_data.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afa0f9f-4034-4ceb-83e2-b39949f918df",
   "metadata": {},
   "source": [
    "## Fitting a support vector machine to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd9e52f5-192a-40f1-bd82-ff4e3e72c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting a support vector machine to the data \n",
    "def fit_classifier(C_value=1.0): \n",
    "    clf = svm.LinearSVC(C=C_value, loss='hinge') \n",
    "    clf.fit(train_data,train_labels) \n",
    "    # Get predictions on training data \n",
    "    train_preds = clf.predict(train_data) \n",
    "    train_error = float(np.sum((train_preds > 0.0) != (train_labels > 0.0)))/len(train_labels) \n",
    "    # Get predictions on test data \n",
    "    test_preds = clf.predict(test_data) \n",
    "    test_error = float(np.sum((test_preds > 0.0) != (test_labels > 0.0)))/len(test_labels) \n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ac0894-1131-4a82-bc3b-550b248f2675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 0.01: train 0.215 test 0.250\n",
      "Error rate for C = 0.10: train 0.074 test 0.174\n",
      "Error rate for C = 1.00: train 0.011 test 0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 10.00: train 0.002 test 0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 100.00: train 0.002 test 0.198\n",
      "Error rate for C = 1000.00: train 0.003 test 0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate for C = 10000.00: train 0.001 test 0.204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cvals = [0.01,0.1,1.0,10.0,100.0,1000.0,10000.0] \n",
    "for c in cvals: \n",
    "    train_error, test_error = fit_classifier(c) \n",
    "    print (\"Error rate for C = %0.2f: train %0.3f test %0.3f\" % (c, train_error, test_error)) \n",
    "#We see that the minimum test error is for C = 1.0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "975e2e8a-7b1b-4512-901d-642e6b97d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Evaluating C by k-fold cross-validation \n",
    "def cross_validation_error(x,y,C_value,k): \n",
    "    n = len(y) \n",
    "    # Randomly shuffle indices \n",
    "    indices = np.random.permutation(n) \n",
    "    # Initialize error \n",
    "    err = 0.0 \n",
    "    # Iterate over partitions \n",
    "    for i in range(k): \n",
    "        # Partition indices \n",
    "        test_indices = indices[int(i*(n/k)):int((i+1)*(n/k) - 1)] \n",
    "        train_indices = np.setdiff1d(indices, test_indices) \n",
    "        # Train classifier with parameter c \n",
    "        clf = svm.LinearSVC(C=C_value, loss='hinge') \n",
    "        clf.fit(x[train_indices], y[train_indices]) \n",
    "        # Get predictions on test partition \n",
    "        preds = clf.predict(x[test_indices]) \n",
    "        # Compute error \n",
    "        err += float(np.sum((preds > 0.0) != (y[test_indices] > 0.0)))/len(test_indices) \n",
    "    return err/k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51022ce6-a670-42de-a197-3a8d15db8a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2241793434747798\n",
      "cross_validation_error: \n",
      "0.2070448371656355\n",
      "cross_validation_error: \n",
      "0.19951923076923078\n",
      "cross_validation_error: \n",
      "0.18917835671342684\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2016846231078159\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1957445899708198\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19259239220051116\n",
      "cross_validation_error: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\.conda\\envs\\TensorEnv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18426521797264223\n"
     ]
    }
   ],
   "source": [
    "#Let us print out the eoees or ifferen vaues of k \n",
    "for k in range(2,10): \n",
    "    print(\"cross_validation_error: \") \n",
    "    print(cross_validation_error(train_data,train_labels,1.0,k)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbebf0-17f6-42a5-858a-0d69d0b4c6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
